{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AFMSlicer","text":"<p>AFMSlicer is a program for processing and analysing Atomic Force Microscopy images of bacterial cell walls.</p> <p>It leverages the TopoStats package for loading and flattening/filtering images and as such follows a similar structure in terms of configuration and design patterns.</p> <p>After filtering/flattening of an image it is then \"sliced\" into an 3-D numpy array of masks which are analysed to obtain statistics on the structure of images at different heights.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions of all forms are welcome, whether that is bug reports, feature requests or questions because our documentation isn't clear.</p> <p>Please refer to the installation instructions for cloning and install the development version of AFMSlicer and its dependencies.</p>"},{"location":"contributing/#cloning-the-repository","title":"Cloning the repository","text":"<p>If you wish to make changes to the code base and are not a collaborator on the repository you will have to fork the repository, clone it, make your changes and the submit a pull request.</p> <pre><code># Collaborator\ngit clone git@github.com:ns-rse/AFMSlicer.git\n# Forked copy\ngit clone git@github.com:&lt;YOUR_GITHUB_USERNAME&gt;/TopoStatsAFMSlicer.git\n</code></pre>"},{"location":"contributing/#install-additional-dependencies","title":"Install Additional Dependencies","text":"<p>If you are to contribute you should install the additional dependencies for undertaking work and enable the pre-commit hooks.</p> <p>If you haven't already create a virtual environment and install the packages.</p> <pre><code>uv venv --python=3.11\nsource .venv/bin/activate\nuv sync\nuv pip install -e \".[dev,docs,tests]\"\n</code></pre>"},{"location":"contributing/#creating-a-branch","title":"Creating a Branch","text":"<p>Typically you will create a branch to make changes on (). It is not compulsory but we try to use a consistent nomenclature for branches that shows who has worked on the branch, the issue it pertains to and a short description of the work. To which end you will see branches with the form <code>&lt;GITHUB_USERNAME&gt;/&lt;GITHUB_ISSUE&gt;-&lt;DESCRIPTION&gt;</code>. Some examples are shown below\u2026</p> Branch User Issue Description <code>ns-rse/5-readme-bagdes</code> <code>ns-rse</code> #5 Adding badges to <code>README.md</code> <p>Here we ensure the <code>main</code> branch is up-to-date and create a new branch <code>ns-rse/13-new-feature</code></p> <pre><code>git switch main\ngit pull\ngit switch -c ns-rse/13-new-feature\n</code></pre> <p>You can now start working on your feature or bug fix making regular commits.</p>"},{"location":"contributing/#software-development","title":"Software Development","text":"<p>To make the codebase easier to maintain we ask that you follow the guidelines below on coding style, linting, typing, documentation and testing. These entail a number of additional dependencies that can be installed with the following command.</p> <pre><code>pip install -e .[dev,tests,docs]\n</code></pre> <p>This will pull in all the dependencies we use for development (<code>dev</code>), tests (<code>tests</code>) and writing documentation (<code>docs</code>).</p>"},{"location":"contributing/#coding-stylelinting","title":"Coding Style/Linting","text":"<p>Using a consistent coding style has many benefits (see Linting : What is all the fluff about?). For this project we aim to adhere to [PEP8 - the style Guide for Python Code] and do so using the formatting linters black and ruff. Ruff implements the checks made by Flake8), isort, mypy and numpydoc-validation. We also like to ensure the code passes pylint which helps identify code duplication and reduces some of the code smells that we are all prone to making. A <code>.pylintrc</code> is included in the repository. These checks are run on all Pull Requests via pre-commit.ci and have to pass before contributions can be merged to <code>main</code>.</p> <p>Many popular IDEs such as VSCode, PyCharm, Spyder and Emacs all have support for integrating these linters into your workflow such that when you save a file the linting/formatting is automatically applied.</p>"},{"location":"contributing/#pre-commit","title":"Pre-commit","text":"<p>pre-commit is a powerful and useful tool that runs hooks on your code prior to making commits. For a more detailed exposition see pre-commit : Protecting your future self. The repository includes <code>pre-commit</code> as a development dependency as well as a <code>.pre-commit-config.yaml</code>. To use these locally you should have already installed all the <code>dev</code> dependencies in your virtual environment. You then need to install <code>pre-commit</code> configuration and hooks (NB this will download specific virtual environments that <code>pre-commit</code> uses when running hooks so the first time this is run may take a little while).</p> <pre><code>pre-commit install --install-hooks\n</code></pre> <p>If these fail then you will not be able to make a commit until they are fixed. Several of the linters will automatically format files so you can simply <code>git add -u .</code> those and try committing straight away. <code>flake8</code> does not correct files automatically so the errors will need manually correcting.</p> <p>If you do not enable and resolve issues reported by <code>pre-commit</code> locally before making a pull request you will find the <code>pre-commit.ci</code> GitHub Action will fail, preventing your Pull Request from being merged. You can shorten the feedback loop and speed up the resolution of errors by enabling <code>pre-commit</code> locally and resolving issues before making your commits.</p>"},{"location":"contributing/#typing","title":"Typing","text":"<p>Whilst Python is a dynamically typed language (that is the type of an object is determined dynamically) the use of Type Hints is expected as it makes reading and understanding the code considerably easier for contributors and the code base more robust. These are checked on commits and pull-requests via a pre-commit hook that runs mypy. For more on Type Hints see PEP483 and PEP484.</p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>All classes, methods and functions should have numpy docstrings defining their functionality, parameters and return values. Pylint will note and report the absence of docstrings by way of the <code>missing-function-docstring</code> condition and the docstrings are checked the the pre-commit hook numpydoc-validation. Further, when new methods that introduce changes to the configuration are incorporated into the package they should be documented under Parameter Configuration. pre-commit has the markdownlint-cli2 hook enabled to lint all Markdown files and will where possible automatically fix things, but some issues need resolving manually.</p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>New features should have unit-tests written and included under the <code>tests/</code> directory to ensure the functions work as expected. The pytest framework is used for running tests along with a number of plugins (syrupy for regression testing; pytest-mpl for testing generated Matplotlib images). In conjunction with pre-commit we leverage pytest-testmon) to run tests on each commit, but as the test suite is large and can take a while to run <code>pytest-testmon</code> restricts tests to only files that have changed (code or tests) or changes in environment variables and dependencies. You will need to create a database locally on first run and so should run the following before undertaking any development.</p> <pre><code>pytest --testmon\n</code></pre> <p>This will create a database (<code>.testmondata</code>) which tracks the current state of the repository, this file is ignored by Git (via <code>.gitignore</code>) but keeps track of the state of the repository and what has changed so that the <code>pre-commit</code> hook <code>Pytest (testmon)</code> only attempts to run the tests when changes have been made to files that impact the tests.</p>"},{"location":"contributing/#debugging","title":"Debugging","text":"<p>To aid with debugging we include the snoop package as a <code>dev</code> dependency. The package is disabled by default, but when you have a class, method or function you wish to debug you should add <code>snoop.install(enabled=True)</code> to the file you wish to debug and use the <code>@snoop</code> decorator around the function/method you wish to debug.</p>"},{"location":"contributing/#configuration","title":"Configuration","text":"<p>As described in Parameter Configuration options are primarily passed to AFMSlicer via a YAML configuration file. When introducing new features that require configuration options you will have to ensure that the default configuration file (<code>afmslicer/default.yaml</code>) is updated to include your options and that corresponding arguments are added to the entry point (please refer to Adding Modules page which covers this). Further the <code>afmslicer.validation.validate.config()</code> function, which checks a valid configuration file with all necessary fields has been passed when invoking <code>afmslicer</code> sub-commands, will also need updating to include new options in the Schema against which validation of configuration files is made.</p>"},{"location":"contributing/#ide-configuration","title":"IDE Configuration","text":"<p>Linters such as <code>black</code>, <code>flake8</code> and <code>pylint</code> can be configured to work with your IDE so that say Black and/or formatting is applied on saving a file or the code is analysed with <code>pylint</code> on saving and errors reported. Setting up and configuring IDEs to work in this manner is beyond the scope of this document but some links to articles on how to do so are provided.</p> <ul> <li>Linting Python in Visual Studio Code</li> <li>Code Analysis \u2014 Spyder   for <code>pylint</code> for Black see   How to use code formatter Black with Spyder.</li> <li>Code Quality Assistance Tips and Tricks, or How to Make Your Code Look Pretty? | PyCharm</li> <li>Reformat and rearrange code | PyCharm</li> <li>Advanced Python Development Workflow in Emacs | Serghei's Blog</li> <li>Getting started with lsp-mode for Python</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>This page details how to setup a Python virtual environment using uv to install and run AFMSlicer.</p>"},{"location":"installation/#virtual-environment","title":"Virtual Environment","text":"<p>We recommend using uv to install and manage your virtual environments but you do not have to. Other options such virtualenvwrapper and MiniForge also allow you to create and manage virtual environments but are not covered here.</p>"},{"location":"installation/#install-uv","title":"Install <code>uv</code>","text":"<p>uv has excellent instructions on how to install the software on different operating systems.</p>"},{"location":"installation/#create-a-virtual-environment","title":"Create a Virtual Environment","text":"<p>To create a virtual environment you should create a directory for undertaking your work, change directory into it and then us <code>uv venv --python 3.11</code>.</p> <p>NB Because of a performance regression in one of TopoStats dependencies, the package Topoly TopoStats only supports Python 3.10 and 3.11. The developers are aware and are hoping this will be resolved in the near future.</p> <pre><code>mkdir AFMSlicer\ncd AFMSlicer\nuv venv --python 3.11\n</code></pre> <p>You can now activate the environment and check that your are using the <code>python</code> binary from that environment.</p> <pre><code>source .venv/bin/activate\nwhich python\npython --version\n</code></pre> <p>You should see output similar to the following although the first line will depend on your operating system and the path where you created the <code>afm_slicing</code> programme.</p> <pre><code>/home/user/work/AFMSlicer\nPython 3.11.13\n</code></pre> <p>If you use direnv to activate virtual environments automatically when you enter them you can add the following to <code>.envrc</code> to activate the environment from within the <code>AFMSlicer</code> directory.</p> <pre><code>echo \"#!/bin/bash\\nsource .venv/bin/activate\" &gt; .envrc\n</code></pre>"},{"location":"installation/#pypi","title":"PyPI","text":"<p>Currently AFMSlicer has not been packaged and released to PyPi, when this changes instructions will be added.</p>"},{"location":"installation/#development","title":"Development","text":"<p>AFMSlicer is in the early stages of development and as such must be installed from the GitHub repository along with development versions of its dependency TopoStats. The steps involved in installing the development version are described below and require that you install and use uv to set things up.</p> <ol> <li>Clone the AFMSlicer repository.</li> <li>Clone the TopoStats repository.</li> <li>Switch to the <code>ns-rse/1102-switching-to-TopoStats-class</code> branch on TopoStats.</li> <li>Activate the virtual environment and synchronise it.</li> <li>Install the development version of TopoStats under the virtual environment    (this will pull in the AFMReader dependency automatically).</li> <li>Install AFMSlicer.</li> </ol> <pre><code>cd ~/work/\ngit clone git@github.com:ns-rse/AFMSlicer.git\ngit clone git@github.com:AFM-SPM/TopoStats.git\ncd TopoStats\ngit checkout ns-rse/1102-switching-to-TopoStats-class\ngit pull\ncd ../AFMSlicer\nsource .venv/bin/activate\nuv sync\nuv pip install -e ../TopoStats/.\nuv pip install -e \".[dev,tests]\"\n</code></pre>"},{"location":"introduction/","title":"Introduction","text":""},{"location":"usage/","title":"Usage","text":""},{"location":"workflow/","title":"Workflow","text":"<p>The overall workflow of processing an image with AFMSlicer is shown below.[^mermaid]</p> --- title: AFMSlicer config:   theme: 'dark' --- flowchart RL  LoadScan(\"`**topostats.io.LoadScan()**            Load the image from AFM file`\") Filter(\"`**topostats.filter.Filters()**          Filter and flatten the image`\") AFMSlicer(\"`**afmslicer.slice.Slice()**             Convert 2D numpy array to 3D numpy array of slices`\") MinMaxHeights(\"`Determine Min/Max Heights`\") SliceRanges(\"`Ranges for Slices given user Requested number`\") BinaryMask(\"`Binary Mask for values within range`\")  subgraph Slicing    MinMaxHeights --&gt; SliceRanges    SliceRanges --&gt; BinaryMask end  subgraph Filtering end   subgraph master     LoadScan --&gt; Filter     Filter --&gt; AFMSlicer end   %%style LoadScan fill:#f2e88c,stroke:#000000 %%style Filter fill:#9ddbd7,stroke:#000000 %%style AFMSlicer fill:#f4a666,stroke:#000000   <p>[^mermaid]:     If modifying this diagram it is recommended to copy and paste the existing     code and adjust in the mermaid.live online tool.</p>"},{"location":"api/","title":"API","text":"<ul> <li><code>afmslicer</code></li> </ul>"}]}